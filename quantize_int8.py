"""
Shield-Ryzen Level 3 â€” INT8 Static Quantization
=================================================
Post-Training Static Quantization (PTQ) on shield_ryzen_v2.onnx
Target: AMD Ryzen AI NPU (XDNA architecture)
Output: shield_ryzen_int8.onnx
"""

import cv2
import numpy as np
import os
import time
import sys

print("=" * 60)
print("  SHIELD-RYZEN LEVEL 3 â€” INT8 QUANTIZATION ENGINE")
print("=" * 60)
print()

script_dir = os.path.dirname(os.path.abspath(__file__))
fp32_model = os.path.join(script_dir, 'shield_ryzen_v2.onnx')
preprocessed_model = os.path.join(script_dir, 'shield_ryzen_v2_prep.onnx')
int8_model = os.path.join(script_dir, 'shield_ryzen_int8.onnx')
calib_dir = os.path.join(script_dir, 'calibration_data')

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  STEP 1: QUANTIZATION PRE-PROCESS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("[STEP 1] Pre-processing ONNX graph...")
from onnxruntime.quantization.shape_inference import quant_pre_process

quant_pre_process(
    fp32_model,
    preprocessed_model,
    skip_symbolic_shape=False
)

prep_size = os.path.getsize(preprocessed_model) / 1024 / 1024
orig_size = os.path.getsize(fp32_model) / 1024 / 1024
print(f"         Original:      {orig_size:.2f} MB")
print(f"         Pre-processed: {prep_size:.2f} MB")
print(f"         âœ… Graph optimized for quantization")
print()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  STEP 2: CALIBRATION DATA CAPTURE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("[STEP 2] Capturing calibration data from webcam...")

import mediapipe as mp

# Use IMAGE mode for reliability (no timestamp issues)
BaseOptions = mp.tasks.BaseOptions
FaceLandmarker = mp.tasks.vision.FaceLandmarker
FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
VisionRunningMode = mp.tasks.vision.RunningMode

landmarker_path = os.path.join(script_dir, 'face_landmarker.task')
landmarker_options = FaceLandmarkerOptions(
    base_options=BaseOptions(model_asset_path=landmarker_path),
    running_mode=VisionRunningMode.IMAGE,  # IMAGE mode â€” more reliable for batch capture
    num_faces=1,
    min_face_detection_confidence=0.4,
)

MEAN = np.array([0.5, 0.5, 0.5], dtype=np.float32)
STD  = np.array([0.5, 0.5, 0.5], dtype=np.float32)
INPUT_SIZE = 299
TARGET_FRAMES = 50

def preprocess_face_np(face_crop):
    """Preprocess face for Xception: 299x299, [-1, 1], NCHW."""
    face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)
    face_resized = cv2.resize(face_rgb, (INPUT_SIZE, INPUT_SIZE))
    face_float = face_resized.astype(np.float32) / 255.0
    face_norm = (face_float - MEAN) / STD
    face_chw = np.transpose(face_norm, (2, 0, 1))
    return np.expand_dims(face_chw, axis=0).astype(np.float32)

os.makedirs(calib_dir, exist_ok=True)
calibration_inputs = []

cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("         âŒ Cannot open webcam!")
    sys.exit(1)

# Give webcam time to initialize
time.sleep(1)
collected = 0

print(f"         ğŸ“¸ Capturing {TARGET_FRAMES} face samples...")
print("         ", end="", flush=True)

with FaceLandmarker.create_from_options(landmarker_options) as landmarker:
    attempts = 0
    while collected < TARGET_FRAMES and attempts < 500:
        success, frame = cap.read()
        if not success:
            attempts += 1
            continue
        
        attempts += 1
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb)
        
        # Use detect() for IMAGE mode
        result = landmarker.detect(mp_image)

        if result.face_landmarks:
            for face_lm in result.face_landmarks:
                h, w, _ = frame.shape
                xs = [lm.x for lm in face_lm]
                ys = [lm.y for lm in face_lm]
                x_min = max(0, int(min(xs) * w) - 10)
                y_min = max(0, int(min(ys) * h) - 10)
                x_max = min(w, int(max(xs) * w) + 10)
                y_max = min(h, int(max(ys) * h) + 10)

                face_crop = frame[y_min:y_max, x_min:x_max]
                if face_crop.size == 0:
                    continue

                tensor = preprocess_face_np(face_crop)
                calibration_inputs.append(tensor)
                
                cv2.imwrite(os.path.join(calib_dir, f"calib_{collected:03d}.jpg"), face_crop)
                collected += 1
                
                if collected % 10 == 0:
                    print(f"[{collected}/{TARGET_FRAMES}] ", end="", flush=True)
                
                if collected >= TARGET_FRAMES:
                    break
        
        # Slight delay for varied frames
        time.sleep(0.1)

cap.release()
print()

# If we couldn't get enough real frames, augment with noise
if collected < TARGET_FRAMES and collected > 0:
    print(f"         âš ï¸  Only captured {collected} frames. Augmenting with variations...")
    base_count = len(calibration_inputs)
    while len(calibration_inputs) < TARGET_FRAMES:
        base = calibration_inputs[len(calibration_inputs) % base_count].copy()
        noise = np.random.normal(0, 0.03, base.shape).astype(np.float32)
        augmented = np.clip(base + noise, -1.0, 1.0)
        calibration_inputs.append(augmented)

if len(calibration_inputs) == 0:
    print("         âŒ No calibration data! Generating synthetic calibration set...")
    # Generate synthetic face-like inputs as fallback
    for i in range(TARGET_FRAMES):
        synthetic = np.random.randn(1, 3, INPUT_SIZE, INPUT_SIZE).astype(np.float32) * 0.5
        calibration_inputs.append(synthetic)

print(f"         âœ… Calibration dataset: {len(calibration_inputs)} samples ({collected} real faces)")
print()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  STEP 3: INT8 STATIC QUANTIZATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("[STEP 3] Performing INT8 Static Quantization...")
print("         Weight: QInt8 | Activation: QUInt8 | Format: QDQ")

from onnxruntime.quantization import (
    quantize_static,
    CalibrationDataReader,
    QuantType,
    QuantFormat,
    CalibrationMethod,
)

class ShieldCalibrationReader(CalibrationDataReader):
    """Feed calibration face crops to the quantizer."""
    
    def __init__(self, calibration_data):
        self.data = calibration_data
        self.index = 0
    
    def get_next(self):
        if self.index >= len(self.data):
            return None
        input_data = {'input': self.data[self.index]}
        self.index += 1
        return input_data
    
    def rewind(self):
        self.index = 0

calib_reader = ShieldCalibrationReader(calibration_inputs)

print(f"         Calibrating {len(calibration_inputs)} samples...")

t_start = time.time()

quantize_static(
    model_input=preprocessed_model,
    model_output=int8_model,
    calibration_data_reader=calib_reader,
    quant_format=QuantFormat.QDQ,
    weight_type=QuantType.QInt8,
    activation_type=QuantType.QUInt8,
    calibrate_method=CalibrationMethod.MinMax,
    per_channel=True,
    extra_options={
        'ActivationSymmetric': False,
        'WeightSymmetric': True,
    }
)

quant_time = time.time() - t_start
int8_size = os.path.getsize(int8_model) / 1024 / 1024

print(f"         â±ï¸  Quantization time: {quant_time:.1f}s")
print(f"         ğŸ“¦ INT8 model size: {int8_size:.2f} MB")
print(f"         ğŸ“‰ Compression: {orig_size:.2f} MB â†’ {int8_size:.2f} MB ({(1-int8_size/orig_size)*100:.0f}% smaller)")
print(f"         âœ… shield_ryzen_int8.onnx created!")
print()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  STEP 4: EFFICIENCY AUDIT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("=" * 60)
print("  STEP 4: FINAL EFFICIENCY AUDIT")
print("=" * 60)
print()

import torch  # For CUDA DLL loading
import onnxruntime as ort

# â”€â”€â”€ Size Benchmark â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("[SIZE BENCHMARK]")
print(f"  FP32 (V2): {orig_size:.2f} MB")
print(f"  INT8 (V3): {int8_size:.2f} MB")
print(f"  Reduction: {(1-int8_size/orig_size)*100:.1f}%")
print(f"  Ratio:     {orig_size/int8_size:.1f}x smaller")
print()

# â”€â”€â”€ Load sessions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
opts = ort.SessionOptions()
opts.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL

print("[LOADING SESSIONS]")
sess_fp32 = ort.InferenceSession(fp32_model, sess_options=opts, providers=providers)
print(f"  FP32 Provider: {sess_fp32.get_providers()[0]}")
sess_int8 = ort.InferenceSession(int8_model, sess_options=opts, providers=providers)
print(f"  INT8 Provider: {sess_int8.get_providers()[0]}")
print()

# â”€â”€â”€ Speed Benchmark â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("[SPEED BENCHMARK] (200 runs each, skip 20 warmup)")

bench_input = np.random.randn(1, 3, 299, 299).astype(np.float32)

# Warmup
for _ in range(20):
    sess_fp32.run(None, {'input': bench_input})
    sess_int8.run(None, {'input': bench_input})

# FP32
fp32_times = []
for _ in range(200):
    start = time.perf_counter()
    sess_fp32.run(None, {'input': bench_input})
    fp32_times.append((time.perf_counter() - start) * 1000)

# INT8
int8_times = []
for _ in range(200):
    start = time.perf_counter()
    sess_int8.run(None, {'input': bench_input})
    int8_times.append((time.perf_counter() - start) * 1000)

fp32_avg = np.mean(fp32_times)
fp32_p95 = np.percentile(fp32_times, 95)
int8_avg = np.mean(int8_times)
int8_p95 = np.percentile(int8_times, 95)
speedup = (fp32_avg - int8_avg) / fp32_avg * 100

print(f"  FP32: avg {fp32_avg:.2f} ms | p95 {fp32_p95:.2f} ms | {1000/fp32_avg:.1f} FPS")
print(f"  INT8: avg {int8_avg:.2f} ms | p95 {int8_p95:.2f} ms | {1000/int8_avg:.1f} FPS")
print(f"  Speedup: {speedup:.1f}%")
print()

# â”€â”€â”€ Accuracy Audit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("[ACCURACY AUDIT] FP32 vs INT8 on real calibration data")

max_diff = 0.0
total_tests = min(len(calibration_inputs), 30)
label_matches = 0

print(f"  {'#':<4} {'FP32 [Fake,Real]':<28} {'INT8 [Fake,Real]':<28} {'Diff':<10} {'Match'}")
print(f"  {'-'*78}")

for i in range(total_tests):
    inp = calibration_inputs[i]
    
    fp32_out = sess_fp32.run(None, {'input': inp})[0]
    int8_out = sess_int8.run(None, {'input': inp})[0]
    
    diff = np.abs(fp32_out - int8_out).max()
    max_diff = max(max_diff, diff)
    
    fp32_label = "REAL" if fp32_out[0, 1] >= 0.89 else ("FAKE" if fp32_out[0, 0] > 0.5 else "WARN")
    int8_label = "REAL" if int8_out[0, 1] >= 0.89 else ("FAKE" if int8_out[0, 0] > 0.5 else "WARN")
    match = "âœ…" if fp32_label == int8_label else "âŒ"
    if fp32_label == int8_label:
        label_matches += 1
    
    if i < 10 or fp32_label != int8_label:
        print(f"  {i+1:<4} {str(fp32_out.round(4)):<28} {str(int8_out.round(4)):<28} {diff:<10.6f} {match}")

if total_tests > 10:
    print(f"  ... ({total_tests - 10} more tests ran)")

print(f"\n  Label agreement:  {label_matches}/{total_tests} ({label_matches/total_tests*100:.1f}%)")
print(f"  Max difference:   {max_diff:.6f}")
print(f"  Accuracy:         {'âœ… PRESERVED' if label_matches == total_tests else 'âš ï¸  MINOR DRIFT' if label_matches/total_tests > 0.95 else 'âŒ DRIFT'}")
print()

# â”€â”€â”€ INT8 Graph Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("[INT8 GRAPH ANALYSIS]")
import onnx
int8_onnx = onnx.load(int8_model)
int8_graph = int8_onnx.graph
op_types = set(n.op_type for n in int8_graph.node)
qdq_count = sum(1 for n in int8_graph.node if n.op_type in ('QuantizeLinear', 'DequantizeLinear'))
print(f"  Total nodes:     {len(int8_graph.node)}")
print(f"  QDQ nodes:       {qdq_count}")
print(f"  Softmax:         {'âœ… Present' if 'Softmax' in op_types else 'âŒ Missing'}")
print(f"  Op types:        {sorted(op_types)}")
print()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  FINAL REPORT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("=" * 60)
print("  ğŸ’ SHIELD-RYZEN LEVEL 3 â€” COMPLETE")
print("=" * 60)
print()
print(f"  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
print(f"  â”‚ METRIC           â”‚ FP32 (V2)    â”‚ INT8 (V3)    â”‚")
print(f"  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
print(f"  â”‚ File Size        â”‚ {orig_size:>8.2f} MB  â”‚ {int8_size:>8.2f} MB  â”‚")
print(f"  â”‚ Latency (avg)    â”‚ {fp32_avg:>8.2f} ms  â”‚ {int8_avg:>8.2f} ms  â”‚")
print(f"  â”‚ FPS              â”‚ {1000/fp32_avg:>8.1f}     â”‚ {1000/int8_avg:>8.1f}     â”‚")
print(f"  â”‚ Label Accuracy   â”‚   100.0%     â”‚ {label_matches/total_tests*100:>8.1f}%   â”‚")
print(f"  â”‚ Max Drift        â”‚     â€”        â”‚ {max_diff:>10.6f} â”‚")
print(f"  â”‚ Compression      â”‚     1x       â”‚ {orig_size/int8_size:>8.1f}x    â”‚")
print(f"  â”‚ QDQ Nodes        â”‚     0        â”‚ {qdq_count:>8d}    â”‚")
print(f"  â”‚ NPU Ready        â”‚     âœ…       â”‚     âœ…       â”‚")
print(f"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
print()
print(f"  ğŸ“ Output: shield_ryzen_int8.onnx ({int8_size:.2f} MB)")
print(f"  ğŸ§¹ Preserved: ffpp_c23.pth + shield_ryzen_v2.onnx")
print()
print("=" * 60)

# Cleanup
if os.path.exists(preprocessed_model):
    os.remove(preprocessed_model)
